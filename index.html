<!DOCTYPE html>
<script src="https://cdn.jsdelivr.net/npm/midi-parser-js@4.0.4/src/main.min.js"></script>
<!-- MIDI Parser, GPL Licensed. https://www.npmjs.com/package/midi-parser-js -->

<h1>Sample Synth</h1>
<p>
  Click on the notes to play them, or upload a MIDI file. Read the code on
  <a rel="noopener noreferer" href="https://github.com/Meshiest/samplesynth">
    Github
  </a>
</p>

<p class="form">
  <label for="midifile">Upload a MIDI file</label>
  <input type="file" id="midifile" />
  <label for="enableDevice">Connect MIDI Device</label>
  <input type="button" id="enableDevice" value="Connect MIDI Device" />
  <label for="sample">Upload a sample (optional)</label>
  <input type="file" id="sample" />
  <label for="sampleNote">Select the note this sample corresponds to</label>
  <select id="sampleNote"></select>
  <label for="volume">Volume</label>
  <input type="range" id="volume" min="0" max="1" step="0.01" value="0.5" />
</p>

<div class="content">
  <div class="notes"></div>
  <div class="metadata-container">
    <div id="progress" class="hidden">
      <div id="progress-bar"></div>
    </div>
    <pre id="metadata"></pre>
  </div>
</div>

<style>
  html,
  body {
    background-color: #ccf;
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
  }

  .form {
    display: flex;
    flex-direction: column;
    margin-bottom: 20px;
  }

  .form label {
    margin-bottom: 5px;
    font-weight: bold;
  }

  .form input[type='file'],
  .form input[type='button'] {
    max-width: 300px;
  }

  .form select,
  .form input[type='range'] {
    max-width: 80px;
  }

  .content {
    position: relative;
  }

  .hidden {
    display: none;
  }

  .metadata-container {
    position: absolute;
    left: 240px;
    top: 0;
  }

  #progress {
    height: 14px;
    width: 120px;
    background-color: #3d3d3d;
    border-radius: 4px;
    overflow: hidden;
  }

  #progress-bar {
    height: 14px;
    background-color: rgb(255, 95, 95);
    border-radius: 4px;
  }

  .notes {
    display: flex;
    flex-direction: column;
    width: 200px;
  }

  .note {
    width: 200px;
    cursor: pointer;
    box-sizing: border-box;
    border: 1px solid rgba(0, 0, 0, 0.2);
    background-color: white;
    padding: 5px;
    display: flex;
    align-items: center;
    justify-content: end;
    border-top-right-radius: 4px;
    border-bottom-right-radius: 4px;
  }

  .note.sharp {
    background-color: black;
    color: white;
    margin-top: -12.5px;
    height: 25px;
    margin-bottom: -12.5px;
    width: 140px;
    z-index: 1;
  }

  .note.playing {
    background-color: #eee;
    width: 220px;
  }

  .note.playing.sharp {
    background-color: #333;
    width: 160px;
  }
</style>

<script>
  const NOTE_NAMES = [
    'C',
    'C#',
    'D',
    'D#',
    'E',
    'F',
    'F#',
    'G',
    'G#',
    'A',
    'A#',
    'B',
  ];

  const notes = document.querySelector('.notes');
  const sampleNotes = document.getElementById('sampleNote');
  for (let i = 1, index = i * 12; i < 8; i++) {
    for (let n of NOTE_NAMES) {
      const note = document.createElement('div');
      note.classList.add('note');
      if (n.includes('#')) {
        note.classList.add('sharp');
      }
      if (i < 3) note.classList.add('hidden');
      note.dataset.note = index++;
      note.textContent = n + i;
      notes.prepend(note);

      const option = document.createElement('option');
      option.value = index - 1;
      option.textContent = n + i;
      sampleNotes.appendChild(option);
    }
  }

  function noteToPitch(n) {
    return Math.pow(2, (n - 69) / 12) * 440;
  }

  let soundData = 'la.ogg';
  const initialNote = 12 * 4; // C4
  sampleNotes.value = initialNote;
  let notePitch = noteToPitch(initialNote);
  let noteVolume = 0.5;

  /** @type {HTMLAudioElement[]} */
  const players = [];
  function playNote(el) {
    let player = players.find(p => p.ended);
    if (!player) {
      player = new Audio();
      players.push(player);
    }

    el.classList.add('playing');
    player.src = soundData;
    player.preservesPitch = false;
    player.volume = noteVolume * noteVolume;
    player.playbackRate = noteToPitch(Number(el.dataset.note)) / notePitch;
    player.play();
    player.onended = () => {
      el.classList.remove('playing');
    };
    return player;
  }

  for (const note of document.querySelectorAll('.note')) {
    note.onclick = () => {
      playNote(note);
    };
  }

  const sleep = ms => new Promise(resolve => setTimeout(resolve, ms));

  document.getElementById('sample').onchange = async e => {
    /** @type {File} */
    const file = e.target.files[0];
    soundData = URL.createObjectURL(file);
    new Audio(soundData).play();
    console.log('Loaded sample:', soundData);
  };

  document.getElementById('sampleNote').onchange = e => {
    notePitch = noteToPitch(Number(e.target.value));
  };

  document.getElementById('volume').oninput = e => {
    noteVolume = e.target.value;
  };

  let playIndex = 0;

  document.getElementById('midifile').onchange = async e => {
    /** @type {File} */
    const file = e.target.files[0];
    const midi = MidiParser.parse(new Uint8Array(await file.arrayBuffer()));
    console.log('Parsed MIDI file:', midi);
    if (!midi) {
      document.getElementById('progress').classList.add('hidden');
      return;
    }
    const myIndex = ++playIndex;

    const bpm = midi.timeDivision;
    const metadata = document.getElementById('metadata');
    metadata.textContent = '';
    document.getElementById('progress').classList.remove('hidden');

    let progressPercent = 0;
    let maxTrackLength = 1;
    const progressBar = document.getElementById('progress-bar');
    progressBar.style.width = '0%';

    const tracks = Array.from({ ...midi.track, length: midi.tracks });

    // walk the tracks to find out the total midi length
    for (const track of tracks) {
      track.index = 0;
      track.progress = 0;
      maxTrackLength = Math.max(
        maxTrackLength,
        track.event.reduce((acc, event) => acc + event.deltaTime, 0)
      );
    }

    console.log('Track length:', (maxTrackLength / bpm).toFixed(3) + 's');

    const start = performance.now();
    while (playIndex === myIndex) {
      const secondsSinceStart = (performance.now() - start) / 1000;

      progressPercent = Math.min(1, secondsSinceStart / (maxTrackLength / bpm));
      progressBar.style.width = `${progressPercent * 100}%`;

      let playing = false;
      for (const track of tracks) {
        // skip this track if it's already finished
        if (track.index >= track.event.length) {
          continue;
        }
        playing = true;

        // iterate the notes not yet played
        for (let i = track.index; i < track.event.length; i++) {
          const event = track.event[i];

          // if the event is in the future, exit early
          if ((event.deltaTime + track.progress) / bpm > secondsSinceStart) {
            break;
          }

          track.progress += event.deltaTime;
          track.index = i + 1;

          // print out metadata
          if (event.type === 255 && event.metaType === 3) {
            metadata.textContent += event.data + '\n';
          }

          /// play the note
          if (event.type === 9) {
            const [note, volume] = event.data;
            const el = document.querySelector(`.note[data-note="${note}"]`);
            if (el && volume) playNote(el);
          }
        }
      }

      if (!playing) break;
      await sleep(0);
    }

    console.log(midi);
  };

  const MIDI_STATUS_NOTE_OFF = 0x8;
  const MIDI_STATUS_NOTE_ON = 0x9;
  const MIDI_STATUS_NOTE_AT = 0xa; // after touch
  const MIDI_STATUS_CC = 0xb; // control change
  const MIDI_STATUS_PGM_CHANGE = 0xc;
  const MIDI_STATUS_CHANNEL_AT = 0xd; // after touch
  const MIDI_STATUS_PITCH_BEND = 0xe;

  const MIDI_STATUS = {
    [0x8]: 'NOTE_OFF',
    [0x9]: 'NOTE_ON',
    [0xa]: 'NOTE_AT',
    [0xb]: 'CC',
    [0xc]: 'PGM_CHANGE',
    [0xd]: 'CHANNEL_AT',
    [0xe]: 'PITCH_BEND',
  };

  class MidiEvent {
    constructor(data) {
      this.statusRaw = (data[0] & 0xf0) >> 4;
      this.status = MIDI_STATUS[this.statusRaw];
      this.channel = data[0] & 0x0f;
      this.param1 = data[1];
      this.param2 = data[2];
    }
  }

  document.getElementById('enableDevice').onclick = async () => {
    /** @type {MIDIAccess} */
    const midi = await navigator
      .requestMIDIAccess()
      .catch(() => location.reload());
    navigator.permissions.query({ name: 'midi', sysex: true }).then(result => {
      if (result.state === 'granted') {
        // Access granted.
        console.log('granted', result);
      } else if (result.state === 'prompt') {
        // Using API will prompt for permission
        console.log('prompt', result);
      }
      console.log('denied', result);
      // Permission was denied by user prompt or permission policy
    });

    for (const [entry, input] of midi.inputs) {
      input.onmidimessage =
        /** @param {MIDIMessageEvent} event */ function onMIDIMessage(event) {
          const e = new MidiEvent(event.data);
          let el, found;

          switch (e.statusRaw) {
            case MIDI_STATUS_NOTE_ON:
              const el = document.querySelector(`[data-note="${e.param1}"]`);
              if (el) playNote(el);

              break;

            case MIDI_STATUS_NOTE_OFF:
              // not implemented
              break;

            case MIDI_STATUS_CC:
              // not implemented
              // (volume control)
              if (e.param1 === 7) {
                const _volume = e.param2 / 127;
              }
              break;
          }
        };

      console.log(
        `Input ${entry} port [type:'${input.type}']` +
          ` id:'${input.id}'` +
          ` manufacturer:'${input.manufacturer}'` +
          ` name:'${input.name}'` +
          ` version:'${input.version}'`
      );
    }
  };
</script>
